{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60EuJAhgQZo4"
      },
      "source": [
        "# 題目\n",
        "- DT + 全類別型條件屬性 + 類別型目標屬性\n",
        "\n",
        "## 注意事項\n",
        "- 深度學習建議使用 Nvidia GPU , 激活 Pytorch CUDA 加速功能 , 在 Colab 推薦使用 Nvidia T4 之上的 GPU 加速訓練與推理速度\n",
        "\n",
        "## Colab 環境介紹\n",
        "- 整體為 VM (虛擬機)\n",
        "- OS : Ubuntu 22.04 LTS\n",
        "- CPU : 虛擬化 CPU 雙核約 2GHz\n",
        "- RAM : 約 12.7 GB , 頻率不一定\n",
        "- Disk : 約 112.6 GB , 讀寫速度不一定\n",
        "\n",
        "## NVIDIA T4 GPU (GPU直通)\n",
        "- NVIDIA CUDA 核心 : 2,560\n",
        "- VRAM : 16 GB GDDR6 , 可用約 15.0 GB , 頻寬320+ GB/s\n",
        "- FP32 : 8.1 TFLOPS\n",
        "- FP16/FP32 : 65 FP16 TFLOPS\n",
        "- INT8 : 130 INT8 TOPS\n",
        "- INT4 : 260 INT4 TOPS\n",
        "- PCle : Gen3 x16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7EicUhGqwF3"
      },
      "source": [
        "## 使用資料集\n",
        "- [Nursery](https://archive.ics.uci.edu/dataset/76/nursery)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w79Is_as2S6F"
      },
      "source": [
        "## 資料處理 - B1143028 詹朝成"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Rf7rH6O9eHo",
        "outputId": "0f6c9488-1b9b-44ab-dc55-03c6971b4e35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.10/dist-packages (from ucimlrepo) (2024.8.30)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.16.0)\n",
            "Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.7\n"
          ]
        }
      ],
      "source": [
        "!pip install ucimlrepo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "i4J499EPM2Fl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# fetch dataset\n",
        "nursery = fetch_ucirepo(id=76)\n",
        "# data (as pandas dataframes)\n",
        "feature , target = nursery.data.features, nursery.data.targets\n",
        "X = nursery.data.features\n",
        "y = nursery.data.targets\n",
        "\n",
        "# 定義每個欄位的數字映射\n",
        "mappings_X = {\n",
        "    'parents': {'usual': 0, 'pretentious': 1, 'great_pret': 2},\n",
        "    'has_nurs': {'proper': 0, 'less_proper': 1, 'improper': 2, 'critical': 3, 'very_crit': 4},\n",
        "    'form': {'complete': 0, 'completed': 1, 'incomplete': 2, 'foster': 3},\n",
        "    'children': {'1': 0, '2': 1, '3': 2, 'more': 3},\n",
        "    'housing': {'convenient': 0, 'less_conv': 1, 'critical': 2},\n",
        "    'finance': {'convenient': 0, 'inconv': 1},\n",
        "    'social': {'nonprob': 0, 'slightly_prob': 1, 'problematic': 2},\n",
        "    'health': {'recommended': 0, 'priority': 1, 'not_recom': 2},\n",
        "}\n",
        "mappings_y = {\n",
        "    'class': {'recommend': 0, 'priority': 1, 'not_recom': 2, 'very_recom': 3, 'spec_prior': 4}\n",
        "}\n",
        "\n",
        "X_mapped = X.copy()\n",
        "y_mapped = y.copy()\n",
        "# 應用每個欄位的數字映射\n",
        "for column, mapping in mappings_X.items():\n",
        "    X_mapped[column] = X_mapped[column].map(mapping)\n",
        "\n",
        "for column, mapping in mappings_y.items():\n",
        "    y_mapped[column] = y_mapped[column].map(mapping)\n",
        "\n",
        "# 將資料轉換為numpy.ndarray\n",
        "X = X_mapped.to_numpy()  # 將特徵轉換為numpy陣列\n",
        "y = y_mapped.to_numpy()  # 將目標轉換為numpy陣列\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LItNHoKfqI_e"
      },
      "source": [
        "## 深度學習 - 軟決策樹 - B1143015 林宣佑"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcL4N-cgeEZy",
        "outputId": "6be5adf1-cefa-4726-ca4b-c06996b758f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "*****CUDA Status*****\n",
            "CUDA Available: True\n",
            "CUDA Device: 0\n",
            "CUDA Device Name: Tesla T4\n",
            "\n",
            "*****Model Status*****\n",
            "SoftDecisionTree(\n",
            "  (fc1): Linear(in_features=8, out_features=150, bias=True)\n",
            "  (fc2): Linear(in_features=150, out_features=150, bias=True)\n",
            "  (fc3): Linear(in_features=150, out_features=150, bias=True)\n",
            "  (fc4): Linear(in_features=150, out_features=150, bias=True)\n",
            "  (fc5): Linear(in_features=150, out_features=5, bias=True)\n",
            ")\n",
            "\n",
            "*****Training Status*****\n",
            "| epoch  10 | lr 0.0047500000 | 2044.20 ms | loss 1032.9462137\n",
            "| epoch  20 | lr 0.0045125000 | 2352.58 ms | loss 789.7935590\n",
            "| epoch  30 | lr 0.0042868750 | 2919.97 ms | loss 768.3578754\n",
            "| epoch  40 | lr 0.0040725312 | 3346.16 ms | loss 765.3095654\n",
            "| epoch  50 | lr 0.0038689047 | 1699.85 ms | loss 763.2318457\n",
            "| epoch  60 | lr 0.0036754595 | 1699.27 ms | loss 761.6527844\n",
            "| epoch  70 | lr 0.0034916865 | 1696.20 ms | loss 761.6656376\n",
            "| epoch  80 | lr 0.0033171022 | 1688.76 ms | loss 759.7716464\n",
            "| epoch  90 | lr 0.0031512470 | 1816.12 ms | loss 759.8185777\n",
            "| epoch 100 | lr 0.0029936847 | 2199.08 ms | loss 761.8267344\n",
            "Training cost: 21.47 seconds\n",
            "\n",
            "*****Eval Status*****\n",
            "Confusion Matrix:\n",
            " [[  0   2   0   0   0]\n",
            " [  0 841   1   0  31]\n",
            " [  0   0 870   0   0]\n",
            " [  0  62   0   0   0]\n",
            " [  0   8   0   0 777]]\n",
            "Accuracy: 95.99%\n",
            "Precision: 93.67%\n",
            "Recall: 95.99%\n",
            "F1 Score: 94.81%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import lr_scheduler\n",
        "import time\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.datasets import make_classification # 生成測試用資料\n",
        "from sklearn.model_selection import train_test_split\n",
        "from huggingface_hub import HfApi, HfFolder, Repository\n",
        "from safetensors.torch import save_file\n",
        "from google.colab import userdata\n",
        "# 檢測設備是否支援 CUDA 加速\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "device = torch.device('cuda:0' if USE_CUDA else 'cpu')\n",
        "print(\"*****CUDA Status*****\")\n",
        "print(f\"CUDA Available: {USE_CUDA}\")\n",
        "if USE_CUDA:\n",
        "    print(f\"CUDA Device: {torch.cuda.current_device()}\")\n",
        "    print(f\"CUDA Device Name: {torch.cuda.get_device_name(device)}\")\n",
        "\n",
        "# 定義軟決策樹 (深度學習模仿決策樹的方案)\n",
        "class SoftDecisionTree(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, tau=1.0):\n",
        "        super(SoftDecisionTree, self).__init__()\n",
        "        self.tau = tau  # 溫度參數，用於 Gumbel-Softmax\n",
        "        # 定義網絡層\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc3 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc4 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc5 = nn.Linear(hidden_dim, output_dim)\n",
        "    def gumbel_softmax(self, logits, tau):\n",
        "        # 生成 Gumbel 噪聲\n",
        "        gumbel_noise = -torch.log(-torch.log(torch.rand_like(logits) + 1e-10) + 1e-10)\n",
        "        y = logits + gumbel_noise\n",
        "        return F.softmax(y / tau, dim=-1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.gumbel_softmax(self.fc2(x), self.tau)\n",
        "        x = self.gumbel_softmax(self.fc3(x), self.tau)\n",
        "        x = F.relu(self.fc4(x))\n",
        "        # 輸出層使用 Softmax 來輸出概率\n",
        "        x = F.softmax(self.fc5(x), dim=-1)\n",
        "        return x\n",
        "\n",
        "# 設定模型各層維度\n",
        "input_dim = 8    # 輸入\n",
        "hidden_dim = 150  # 隱藏 , 像神經一樣的概念\n",
        "output_dim = 5   # 輸出\n",
        "\n",
        "# 轉換為 tensor 並移動到設備上\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long).to(device).squeeze()\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.long).to(device).squeeze()\n",
        "\n",
        "\n",
        "# 訓練參數設置\n",
        "batch_size = 128  # 批次大小\n",
        "epochs = 100     # 訓練次數\n",
        "lr = 5e-3        # 學習率\n",
        "criterion = nn.CrossEntropyLoss()  # 損失函數\n",
        "initial_tau = 5.0\n",
        "final_tau = 0.1\n",
        "tau_decay_rate = 0.99 # 每次 epoch 都降低 1%\n",
        "\n",
        "\n",
        "# 模型建立並移動到 device (CPU 或 GPU)\n",
        "model = SoftDecisionTree(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, tau=initial_tau).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)  # 優化器\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.95)  # 調節學習率工具\n",
        "print(\"\\n*****Model Status*****\")\n",
        "print(model)  # 顯示模型結構\n",
        "\n",
        "print(\"\\n*****Training Status*****\")\n",
        "# 訓練模型\n",
        "log_loss = 0\n",
        "log_training_time = 0\n",
        "train_start = time.time()\n",
        "for epoch in range(1,epochs+1):\n",
        "    model.train()  # 將模型設置為訓練模式\n",
        "    model.tau = max(final_tau, initial_tau * (tau_decay_rate ** epoch))\n",
        "    total_loss = 0 # 紀錄 LOSS\n",
        "    start_time = time.time()  # 記錄當前epoch的開始時間\n",
        "    for i in range(0, len(X_train_tensor), batch_size):\n",
        "        batch_X = X_train_tensor[i:i+batch_size]  # 從訓練集中取出一個批次的特徵數據\n",
        "        batch_y = y_train_tensor[i:i+batch_size]  # 從訓練集中取出一個批次的目標數據\n",
        "        outputs = model(batch_X)  # 獲取模型的預測結果\n",
        "        loss = criterion(outputs, batch_y)  # 計算模型的損失\n",
        "        optimizer.zero_grad()  # 梯度反向傳播和參數更新\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    scheduler.step()  # 每個epoch結束後調整學習率(記數)\n",
        "    log_training_time += time.time() - start_time # 加上單次訓練時間\n",
        "    log_loss += total_loss # 加上單次 LOSS\n",
        "    # 每十次輸出訓練狀態 , 10 次的訓練時間總和 , 10 次的LOSS總和\n",
        "    if epoch % 10 == 0:\n",
        "        print('| epoch {:3d} | lr {:02.10f} | {:5.2f} ms | loss {:5.7f}'.format(\n",
        "            epoch, scheduler.get_last_lr()[0], log_training_time * 1000, log_loss))\n",
        "        log_training_time = 0 # 重新計時\n",
        "        log_loss = 0 # 重新計算 LOSS\n",
        "\n",
        "train_times = time.time() - train_start  # 計算整個訓練過程的總執行時間\n",
        "print(f\"Training cost: {train_times:.2f} seconds\")  # 打印整個訓練過程的執行時間\n",
        "\n",
        "\n",
        "# 混淆矩陣和評估指標\n",
        "print(\"\\n*****Eval Status*****\")\n",
        "model.eval()\n",
        "test_outputs = model(X_test_tensor)\n",
        "\n",
        "# 使用 torch.argmax 獲取預測標籤\n",
        "predicted_labels = torch.argmax(test_outputs, dim=1).detach().cpu().numpy()\n",
        "actual_labels = y_test_tensor.cpu().numpy()\n",
        "\n",
        "# 打印混淆矩陣\n",
        "labels = list(range(output_dim))\n",
        "conf_matrix = confusion_matrix(actual_labels, predicted_labels, labels=labels)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "\n",
        "# 打印 正確率 , 精確率 , 召回率 , F1-score\n",
        "print(f\"Accuracy: {accuracy_score(actual_labels, predicted_labels) * 100:.2f}%\")\n",
        "print(f\"Precision: {precision_score(actual_labels, predicted_labels, average='weighted', zero_division=0) * 100:.2f}%\")\n",
        "print(f\"Recall: {recall_score(actual_labels, predicted_labels, average='weighted', zero_division=0) * 100:.2f}%\")\n",
        "print(f\"F1 Score: {f1_score(actual_labels, predicted_labels, average='weighted', zero_division=0) * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iqduOlZOWEN",
        "outputId": "9638967d-d30d-4223-b33a-f87e0dc40a42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "建構儲存庫操作時發生錯誤: 409 Client Error: Conflict for url: https://huggingface.co/api/repos/create (Request ID: Root=1-67321e26-1a85e44e4863b5b007f17e6c;3f9aeafa-0d8d-4f4c-9c6c-5c814e2267e1)\n",
            "\n",
            "You already created this model repo\n",
            "模型成功保存於 soft_decision_tree.safetensors。\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'Repository' (from 'huggingface_hub.repository') is deprecated and will be removed from version '1.0'. Please prefer the http-based alternatives instead. Given its large adoption in legacy code, the complete removal is only planned on next major release.\n",
            "For more details, please read https://huggingface.co/docs/huggingface_hub/concepts/git_vs_http.\n",
            "  warnings.warn(warning_message, FutureWarning)\n",
            "Cloning https://huggingface.co/TsukiOwO/soft_decision_tree into local empty directory.\n",
            "WARNING:huggingface_hub.repository:Cloning https://huggingface.co/TsukiOwO/soft_decision_tree into local empty directory.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "已複製儲存庫: TsukiOwO/soft_decision_tree\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "To https://huggingface.co/TsukiOwO/soft_decision_tree\n",
            "   de3195f..6cc47d1  main -> main\n",
            "\n",
            "WARNING:huggingface_hub.repository:To https://huggingface.co/TsukiOwO/soft_decision_tree\n",
            "   de3195f..6cc47d1  main -> main\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "模型已上傳至 Hugging Face: TsukiOwO/soft_decision_tree\n"
          ]
        }
      ],
      "source": [
        "from huggingface_hub import HfApi, Repository\n",
        "from safetensors.torch import save_file\n",
        "import os\n",
        "import shutil\n",
        "# 模型保存\n",
        "USER_NAME = \"TsukiOwO\"\n",
        "MODEL_NAME = \"soft_decision_tree\"\n",
        "model_save_path = f\"{MODEL_NAME}.safetensors\"\n",
        "repo_name = f\"{USER_NAME}/{MODEL_NAME}\"\n",
        "api_token = userdata.get('Colab_ALL')\n",
        "\n",
        "# Hugging Face API\n",
        "api = HfApi()\n",
        "\n",
        "\n",
        "# 建構儲存庫\n",
        "try:\n",
        "    api.create_repo(repo_id=repo_name, token=api_token, private=False)\n",
        "    print(f\"儲存庫 '{repo_name}' 建立成功。\")\n",
        "except Exception as e:\n",
        "    print(f\"建構儲存庫操作時發生錯誤: {e}\")\n",
        "\n",
        "# 提取模型權重並保存為 safetensors 格式\n",
        "model_weights = {name: tensor for name, tensor in model.state_dict().items()}  # 提取每個張量\n",
        "save_file(model_weights, model_save_path)\n",
        "\n",
        "# 檢查檔案是否成功保存\n",
        "if os.path.exists(model_save_path):\n",
        "    print(f\"模型成功保存於 {model_save_path}。\")\n",
        "else:\n",
        "    print(f\"模型保存失敗於 {model_save_path}。\")\n",
        "\n",
        "# 設定 Git 用戶名和電子郵件\n",
        "!git config --global user.email \"a0985821880@gmail.com\"\n",
        "!git config --global user.name \"TsukiSama9292\"\n",
        "\n",
        "# 上傳模型到 Hugging Face\n",
        "try:\n",
        "    repo = Repository(repo_name, clone_from=repo_name, token=api_token)\n",
        "    print(f\"已複製儲存庫: {repo_name}\")\n",
        "\n",
        "    # 拉取最新的更改\n",
        "    repo.git_pull()\n",
        "\n",
        "    # 移動檔案到儲存庫目錄\n",
        "    shutil.move(model_save_path, os.path.join(repo.local_dir, model_save_path))\n",
        "\n",
        "    # 檢查檔案是否存在\n",
        "    if os.path.exists(os.path.join(repo.local_dir, model_save_path)):\n",
        "        repo.git_add(model_save_path)\n",
        "        repo.git_commit(\"新增 soft decision tree 模型於 safetensors 格式\")\n",
        "        repo.git_push()\n",
        "        print(f\"模型已上傳至 Hugging Face: {repo_name}\")\n",
        "    else:\n",
        "        print(f\"檔案 '{model_save_path}' 不存在於儲存庫目錄中，無法上傳。\")\n",
        "except Exception as e:\n",
        "    print(f\"儲存庫操作時發生錯誤: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXJ6lqOfmXRo"
      },
      "source": [
        "## 深度學習 - 測試模型 - B1143015 林宣佑, B1143028 詹朝成(架構修改)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPjwl2mykD3c",
        "outputId": "b1d2ac36-9547-438c-f331-4af35f10b570"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "*****CUDA Status*****\n",
            "CUDA Available: True\n",
            "CUDA Device: 0\n",
            "CUDA Device Name: Tesla T4\n",
            "\n",
            "*****Model Status*****\n",
            "ReLU(\n",
            "  (fc1): Linear(in_features=8, out_features=5, bias=True)\n",
            ")\n",
            "\n",
            "*****Training Status*****\n",
            "| epoch  10 | lr 0.0047500000 | 768.83 ms | loss 591.8643637\n",
            "| epoch  20 | lr 0.0045125000 | 786.69 ms | loss 329.0077802\n",
            "| epoch  30 | lr 0.0042868750 | 990.10 ms | loss 268.7108512\n",
            "| epoch  40 | lr 0.0040725312 | 765.89 ms | loss 236.6843954\n",
            "| epoch  50 | lr 0.0038689047 | 1069.31 ms | loss 217.2248575\n",
            "| epoch  60 | lr 0.0036754595 | 771.54 ms | loss 204.7096278\n",
            "| epoch  70 | lr 0.0034916865 | 779.90 ms | loss 196.3564617\n",
            "| epoch  80 | lr 0.0033171022 | 866.48 ms | loss 190.6130126\n",
            "| epoch  90 | lr 0.0031512470 | 784.72 ms | loss 186.5673067\n",
            "| epoch 100 | lr 0.0029936847 | 761.42 ms | loss 183.6618306\n",
            "Training cost: 8.35 seconds\n",
            "\n",
            "*****Eval Status*****\n",
            "Confusion Matrix:\n",
            " [[  0   0   0   2   0]\n",
            " [  0 791   0   2  80]\n",
            " [  0   0 870   0   0]\n",
            " [  0  46   0  16   0]\n",
            " [  0  99   0   0 686]]\n",
            "Accuracy: 91.17%\n",
            "Precision: 91.06%\n",
            "Recall: 91.17%\n",
            "F1 Score: 90.74%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import lr_scheduler\n",
        "import time\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from huggingface_hub import HfApi, HfFolder, Repository\n",
        "from safetensors.torch import save_file\n",
        "from google.colab import userdata\n",
        "# 檢測設備是否支援 CUDA 加速\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "device = torch.device('cuda:0' if USE_CUDA else 'cpu')\n",
        "print(\"*****CUDA Status*****\")\n",
        "print(f\"CUDA Available: {USE_CUDA}\")\n",
        "if USE_CUDA:\n",
        "    print(f\"CUDA Device: {torch.cuda.current_device()}\")\n",
        "    print(f\"CUDA Device Name: {torch.cuda.get_device_name(device)}\")\n",
        "\n",
        "class ReLU(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(ReLU, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        return x\n",
        "\n",
        "\n",
        "# 設定模型各層維度\n",
        "input_dim = 8    # 輸入\n",
        "output_dim = 5   # 輸出\n",
        "\n",
        "# 轉換為 tensor 並移動到設備上\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long).to(device).squeeze()\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.long).to(device).squeeze()\n",
        "\n",
        "# 訓練參數設置\n",
        "batch_size = 128  # 批次大小\n",
        "epochs = 100     # 訓練次數\n",
        "lr = 5e-3        # 學習率\n",
        "criterion = nn.CrossEntropyLoss()  # 損失函數\n",
        "\n",
        "# 模型建立並移動到 device (CPU 或 GPU)\n",
        "model = ReLU(input_dim=input_dim, output_dim=output_dim).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)  # 優化器\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.95)  # 調節學習率工具\n",
        "print(\"\\n*****Model Status*****\")\n",
        "print(model)  # 顯示模型結構\n",
        "\n",
        "print(\"\\n*****Training Status*****\")\n",
        "# 訓練模型\n",
        "log_loss = 0\n",
        "log_training_time = 0\n",
        "train_start = time.time()\n",
        "for epoch in range(1,epochs+1):\n",
        "    model.train()  # 將模型設置為訓練模式\n",
        "    total_loss = 0 # 紀錄 LOSS\n",
        "    start_time = time.time()  # 記錄當前epoch的開始時間\n",
        "    for i in range(0, len(X_train_tensor), batch_size):\n",
        "        batch_X = X_train_tensor[i:i+batch_size]  # 從訓練集中取出一個批次的特徵數據\n",
        "        batch_y = y_train_tensor[i:i+batch_size]  # 從訓練集中取出一個批次的目標數據\n",
        "        outputs = model(batch_X)  # 獲取模型的預測結果\n",
        "        loss = criterion(outputs, batch_y)  # 計算模型的損失\n",
        "        optimizer.zero_grad()  # 梯度反向傳播和參數更新\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    scheduler.step()  # 每個epoch結束後調整學習率(記數)\n",
        "    log_training_time += time.time() - start_time # 加上單次訓練時間\n",
        "    log_loss += total_loss # 加上單次 LOSS\n",
        "    # 每十次輸出訓練狀態 , 10 次的訓練時間總和 , 10 次的LOSS總和\n",
        "    if epoch % 10 == 0:\n",
        "        print('| epoch {:3d} | lr {:02.10f} | {:5.2f} ms | loss {:5.7f}'.format(\n",
        "            epoch, scheduler.get_last_lr()[0], log_training_time * 1000, log_loss))\n",
        "        log_training_time = 0 # 重新計時\n",
        "        log_loss = 0 # 重新計算 LOSS\n",
        "\n",
        "train_times = time.time() - train_start  # 計算整個訓練過程的總執行時間\n",
        "print(f\"Training cost: {train_times:.2f} seconds\")  # 打印整個訓練過程的執行時間\n",
        "\n",
        "\n",
        "# 混淆矩陣和評估指標\n",
        "print(\"\\n*****Eval Status*****\")\n",
        "model.eval()\n",
        "test_outputs = model(X_test_tensor)\n",
        "\n",
        "# 使用 torch.argmax 獲取預測標籤\n",
        "predicted_labels = torch.argmax(test_outputs, dim=1).detach().cpu().numpy()\n",
        "actual_labels = y_test_tensor.cpu().numpy()\n",
        "\n",
        "# 打印混淆矩陣\n",
        "labels = list(range(output_dim))\n",
        "conf_matrix = confusion_matrix(actual_labels, predicted_labels, labels=labels)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "\n",
        "# 打印 正確率 , 精確率 , 召回率\n",
        "print(f\"Accuracy: {accuracy_score(actual_labels, predicted_labels) * 100:.2f}%\")\n",
        "print(f\"Precision: {precision_score(actual_labels, predicted_labels, average='weighted', zero_division=0) * 100:.2f}%\")\n",
        "print(f\"Recall: {recall_score(actual_labels, predicted_labels, average='weighted', zero_division=0) * 100:.2f}%\")\n",
        "print(f\"F1 Score: {f1_score(actual_labels, predicted_labels, average='weighted', zero_division=0) * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fL9O-LbUEvhC"
      },
      "source": [
        "## 深度學習 - 自注意力模型 - B1143015 林宣佑, B1143028 詹朝成(架構修改)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpdWUURpEu4U",
        "outputId": "7b47382f-cc0a-4239-a32f-dc305029f35e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "*****CUDA Status*****\n",
            "CUDA Available: True\n",
            "CUDA Device: 0\n",
            "CUDA Device Name: Tesla T4\n",
            "\n",
            "*****Model Status*****\n",
            "AttentionWithReLU(\n",
            "  (relu1): Linear(in_features=8, out_features=100, bias=True)\n",
            "  (attention): SelfAttention(\n",
            "    (query): Linear(in_features=100, out_features=100, bias=True)\n",
            "    (key): Linear(in_features=100, out_features=100, bias=True)\n",
            "    (value): Linear(in_features=100, out_features=100, bias=True)\n",
            "  )\n",
            "  (relu2): Linear(in_features=100, out_features=5, bias=True)\n",
            ")\n",
            "\n",
            "*****Training Status*****\n",
            "| epoch  10 | lr 0.0047500000 | 1849.44 ms | loss 187.1027194\n",
            "| epoch  20 | lr 0.0045125000 | 1508.15 ms | loss 44.3221867\n",
            "| epoch  30 | lr 0.0042868750 | 1508.10 ms | loss 38.7977894\n",
            "| epoch  40 | lr 0.0040725312 | 1517.08 ms | loss 14.7306274\n",
            "| epoch  50 | lr 0.0038689047 | 1492.63 ms | loss 11.1443813\n",
            "| epoch  60 | lr 0.0036754595 | 1510.44 ms | loss 6.9109536\n",
            "| epoch  70 | lr 0.0034916865 | 1525.84 ms | loss 0.0401645\n",
            "| epoch  80 | lr 0.0033171022 | 1911.07 ms | loss 0.0144728\n",
            "| epoch  90 | lr 0.0031512470 | 1675.70 ms | loss 0.0075288\n",
            "| epoch 100 | lr 0.0029936847 | 1515.85 ms | loss 0.0043879\n",
            "Training cost: 16.02 seconds\n",
            "\n",
            "*****Eval Status*****\n",
            "Confusion Matrix:\n",
            " [[  0   0   0   2   0]\n",
            " [  0 872   0   0   1]\n",
            " [  0   0 870   0   0]\n",
            " [  0   0   0  62   0]\n",
            " [  0   0   0   0 785]]\n",
            "Accuracy: 99.88%\n",
            "Precision: 99.81%\n",
            "Recall: 99.88%\n",
            "F1 Score: 99.85%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import lr_scheduler\n",
        "import time\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from huggingface_hub import HfApi, HfFolder, Repository\n",
        "from safetensors.torch import save_file\n",
        "from google.colab import userdata\n",
        "# 檢測設備是否支援 CUDA 加速\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "device = torch.device('cuda:0' if USE_CUDA else 'cpu')\n",
        "print(\"*****CUDA Status*****\")\n",
        "print(f\"CUDA Available: {USE_CUDA}\")\n",
        "if USE_CUDA:\n",
        "    print(f\"CUDA Device: {torch.cuda.current_device()}\")\n",
        "    print(f\"CUDA Device Name: {torch.cuda.get_device_name(device)}\")\n",
        "\n",
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(SelfAttention, self).__init__()\n",
        "        self.query = nn.Linear(input_dim, input_dim)\n",
        "        self.key = nn.Linear(input_dim, input_dim)\n",
        "        self.value = nn.Linear(input_dim, input_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        q = self.query(x)\n",
        "        k = self.key(x)\n",
        "        v = self.value(x)\n",
        "\n",
        "        attention_scores = torch.matmul(q, k.transpose(-2, -1)) / np.sqrt(x.size(-1))  # 計算注意力權重\n",
        "        attention_probs = torch.softmax(attention_scores, dim=-1)\n",
        "\n",
        "        return torch.matmul(attention_probs, v)  # 聚焦重要特徵\n",
        "\n",
        "# 定義結合模型：自注意力 + ReLU\n",
        "class AttentionWithReLU(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(AttentionWithReLU, self).__init__()\n",
        "        self.relu1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.attention = SelfAttention(hidden_dim)\n",
        "        self.relu2 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.relu1(x))\n",
        "        x = self.attention(x)  # 自注意力層處理輸入\n",
        "        x = F.relu(self.relu2(x))\n",
        "        return x\n",
        "\n",
        "# 設定模型各層維度\n",
        "input_dim = 8    # 輸入\n",
        "hidden_dim = 100  # 隱藏 , 像神經一樣的概念\n",
        "output_dim = 5   # 輸出\n",
        "\n",
        "# 轉換為 tensor 並移動到設備上\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long).to(device).squeeze()\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.long).to(device).squeeze()\n",
        "\n",
        "# 訓練參數設置\n",
        "batch_size = 128  # 批次大小\n",
        "epochs = 100     # 訓練次數\n",
        "lr = 5e-3        # 學習率\n",
        "criterion = nn.CrossEntropyLoss()  # 損失函數\n",
        "\n",
        "# 模型建立並移動到 device (CPU 或 GPU)\n",
        "model = AttentionWithReLU(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)  # 優化器\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.95)  # 調節學習率工具\n",
        "print(\"\\n*****Model Status*****\")\n",
        "print(model)  # 顯示模型結構\n",
        "\n",
        "print(\"\\n*****Training Status*****\")\n",
        "# 訓練模型\n",
        "log_loss = 0\n",
        "log_training_time = 0\n",
        "train_start = time.time()\n",
        "for epoch in range(1,epochs+1):\n",
        "    model.train()  # 將模型設置為訓練模式\n",
        "    total_loss = 0 # 紀錄 LOSS\n",
        "    start_time = time.time()  # 記錄當前epoch的開始時間\n",
        "    for i in range(0, len(X_train_tensor), batch_size):\n",
        "        batch_X = X_train_tensor[i:i+batch_size]  # 從訓練集中取出一個批次的特徵數據\n",
        "        batch_y = y_train_tensor[i:i+batch_size]  # 從訓練集中取出一個批次的目標數據\n",
        "        outputs = model(batch_X)  # 獲取模型的預測結果\n",
        "        loss = criterion(outputs, batch_y)  # 計算模型的損失\n",
        "        optimizer.zero_grad()  # 梯度反向傳播和參數更新\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    scheduler.step()  # 每個epoch結束後調整學習率(記數)\n",
        "    log_training_time += time.time() - start_time # 加上單次訓練時間\n",
        "    log_loss += total_loss # 加上單次 LOSS\n",
        "    # 每十次輸出訓練狀態 , 10 次的訓練時間總和 , 10 次的LOSS總和\n",
        "    if epoch % 10 == 0:\n",
        "        print('| epoch {:3d} | lr {:02.10f} | {:5.2f} ms | loss {:5.7f}'.format(\n",
        "            epoch, scheduler.get_last_lr()[0], log_training_time * 1000, log_loss))\n",
        "        log_training_time = 0 # 重新計時\n",
        "        log_loss = 0 # 重新計算 LOSS\n",
        "\n",
        "train_times = time.time() - train_start  # 計算整個訓練過程的總執行時間\n",
        "print(f\"Training cost: {train_times:.2f} seconds\")  # 打印整個訓練過程的執行時間\n",
        "\n",
        "\n",
        "# 混淆矩陣和評估指標\n",
        "print(\"\\n*****Eval Status*****\")\n",
        "model.eval()\n",
        "test_outputs = model(X_test_tensor)\n",
        "\n",
        "# 使用 torch.argmax 獲取預測標籤\n",
        "predicted_labels = torch.argmax(test_outputs, dim=1).detach().cpu().numpy()\n",
        "actual_labels = y_test_tensor.cpu().numpy()\n",
        "\n",
        "# 打印混淆矩陣\n",
        "labels = list(range(output_dim))\n",
        "conf_matrix = confusion_matrix(actual_labels, predicted_labels, labels=labels)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "\n",
        "# 打印 正確率 , 精確率 , 召回率\n",
        "print(f\"Accuracy: {accuracy_score(actual_labels, predicted_labels) * 100:.2f}%\")\n",
        "print(f\"Precision: {precision_score(actual_labels, predicted_labels, average='weighted', zero_division=0) * 100:.2f}%\")\n",
        "print(f\"Recall: {recall_score(actual_labels, predicted_labels, average='weighted', zero_division=0) * 100:.2f}%\")\n",
        "print(f\"F1 Score: {f1_score(actual_labels, predicted_labels, average='weighted', zero_division=0) * 100:.2f}%\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "w79Is_as2S6F",
        "LItNHoKfqI_e",
        "wXJ6lqOfmXRo"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
